@incollection{burelCimpleKGContinuouslyUpdated2025,
  title = {{{CimpleKG}}: {{A Continuously Updated Knowledge Graph}} on {{Misinformation}}, {{Factors}} and {{Fact-Checks}}},
  shorttitle = {{{CimpleKG}}},
  booktitle = {The {{Semantic Web}} – {{ISWC}} 2024},
  author = {Burel, Grégoire and Mensio, Martino and Peskine, Youri and Troncy, Raphael and Papotti, Paolo and Alani, Harith},
  editor = {Demartini, Gianluca and Hose, Katja and Acosta, Maribel and Palmonari, Matteo and Cheng, Gong and Skaf-Molli, Hala and Ferranti, Nicolas and Hernández, Daniel and Hogan, Aidan},
  date = {2025},
  volume = {15233},
  pages = {97--114},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-77847-6_6},
  url = {https://link.springer.com/10.1007/978-3-031-77847-6_6},
  urldate = {2025-08-27},
  isbn = {978-3-031-77846-9 978-3-031-77847-6},
  langid = {english},
  file = {/Users/ale/Zotero/storage/Q5IXCKQ2/Burel et al. - 2025 - CimpleKG A Continuously Updated Knowledge Graph on Misinformation, Factors and Fact-Checks.pdf}
}

@online{chenCanLLMGeneratedMisinformation2024,
  title = {Can {{LLM-Generated Misinformation Be Detected}}?},
  author = {Chen, Canyu and Shu, Kai},
  date = {2024-04-23},
  eprint = {2309.13788},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.13788},
  url = {http://arxiv.org/abs/2309.13788},
  urldate = {2025-08-28},
  abstract = {The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures.},
  pubstate = {prepublished},
  version = {5},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/ale/Zotero/storage/LILNRKHG/Chen and Shu - 2024 - Can LLM-Generated Misinformation Be Detected.pdf;/Users/ale/Zotero/storage/P6CL8TS5/2309.html}
}

@article{chenCombatingMisinformationAge2024,
  title = {Combating Misinformation in the Age of {{LLMs}}: {{Opportunities}} and Challenges},
  shorttitle = {Combating Misinformation in the Age of {{LLMs}}},
  author = {Chen, Canyu and Shu, Kai},
  date = {2024},
  journaltitle = {AI Magazine},
  volume = {45},
  number = {3},
  pages = {354--368},
  issn = {2371-9621},
  doi = {10.1002/aaai.12188},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aaai.12188},
  urldate = {2025-08-28},
  abstract = {Misinformation such as fake news and rumors is a serious threat for information ecosystems and public trust. The emergence of large language models (LLMs) has great potential to reshape the landscape of combating misinformation. Generally, LLMs can be a double-edged sword in the fight. On the one hand, LLMs bring promising opportunities for combating misinformation due to their profound world knowledge and strong reasoning abilities. Thus, one emerging question is: can we utilize LLMs to combat misinformation? On the other hand, the critical challenge is that LLMs can be easily leveraged to generate deceptive misinformation at scale. Then, another important question is: how to combat LLM-generated misinformation? In this paper, we first systematically review the history of combating misinformation before the advent of LLMs. Then we illustrate the current efforts and present an outlook for these two fundamental questions, respectively. The goal of this survey paper is to facilitate the progress of utilizing LLMs for fighting misinformation and call for interdisciplinary efforts from different stakeholders for combating LLM-generated misinformation.},
  langid = {english},
  file = {/Users/ale/Zotero/storage/UYKRK77Q/Chen and Shu - 2024 - Combating misinformation in the age of LLMs Opportunities and challenges.pdf;/Users/ale/Zotero/storage/HGMLGDUX/aaai.html}
}

@inproceedings{chenReviewApplicationsKnowledge2023,
  title = {Review on {{Applications}} of {{Knowledge Graph}} in {{Software Development}}},
  booktitle = {2023 6th {{International Symposium}} on {{Autonomous Systems}} ({{ISAS}})},
  author = {Chen, Zhihua and Zhao, Ming and Yang, Luchang and Xu, Fan and Ji, Hongxia and Wu, Peiya and Zhang, Kai and Dong, Xiaogang and Li, Xiaofeng},
  date = {2023-06},
  pages = {1--7},
  doi = {10.1109/ISAS59543.2023.10164597},
  url = {https://ieeexplore.ieee.org/document/10164597},
  urldate = {2025-08-27},
  abstract = {Knowledge graph (KG) can represent the domain knowledge in the structural entities and relations and have become a popular AI technique. Software knowledge provides a deep understanding of the software development process. In this paper, we firstly provide a brief review on the related techniques, construction methods and applications of KG in the software development process. Then, we detailedly review and discuss the specific applications of KG in the whole software development process, including the phases of software requirement analysis, software design, software testing, software vulnerability detection, software bug detection and software fault diagnosis, respectively. Moreover, this paper provides some unsolved problems about the KG’s applications in the field of spacecraft control software development to facilitate future research.},
  eventtitle = {2023 6th {{International Symposium}} on {{Autonomous Systems}} ({{ISAS}})},
  keywords = {Autonomous systems,Computer bugs,Fault diagnosis,knowledge graph,Process control,requirement analysis,software,software bug detection,software design,Software design,software fault diagnosis,software testing,Software testing,software vulnerability detection,Space vehicles,spacecraft control},
  file = {/Users/ale/Zotero/storage/CGB6QN85/Chen et al. - 2023 - Review on Applications of Knowledge Graph in Software Development.pdf}
}

@online{edgeLocalGlobalGraph2025,
  title = {From {{Local}} to {{Global}}: {{A Graph RAG Approach}} to {{Query-Focused Summarization}}},
  shorttitle = {From {{Local}} to {{Global}}},
  author = {Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Metropolitansky, Dasha and Ness, Robert Osazuwa and Larson, Jonathan},
  date = {2025-02-19},
  eprint = {2404.16130},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.16130},
  url = {http://arxiv.org/abs/2404.16130},
  urldate = {2025-08-27},
  abstract = {The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as "What are the main themes in the dataset?", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text. Our approach uses an LLM to build a graph index in two stages: first, to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/Users/ale/Zotero/storage/AUEBTHJP/Edge et al. - 2025 - From Local to Global A Graph RAG Approach to Query-Focused Summarization.pdf;/Users/ale/Zotero/storage/786T67VS/2404.html}
}

@inproceedings{fatahibayatFactBenchDynamicBenchmark2025,
  title = {{{FactBench}}: {{A Dynamic Benchmark}} for {{In-the-Wild Language Model Factuality Evaluation}}},
  shorttitle = {{{FactBench}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Fatahi Bayat, Farima and Zhang, Lechen and Munir, Sheza and Wang, Lu},
  editor = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  date = {2025-07},
  pages = {33090--33110},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.1587},
  url = {https://aclanthology.org/2025.acl-long.1587/},
  urldate = {2025-08-27},
  abstract = {The rapid adoption of language models (LMs) across diverse applications has raised concerns about their factuality, i.e., their consistency with real-world facts. We introduce VERIFY, an evidence-based evaluation pipeline that measures LMs' factuality in real-world user interactions. VERIFY considers the verifiability of LM-generated content and categorizes content units as Supported, Unsupported, or Undecidable based on Web-retrieved evidence. Importantly, factuality judgment by VERIFY more strongly correlates with human evaluations than existing methods. Using VERIFY, we identify “hallucination prompts,” i.e., those that frequently elicit factual errors in LM responses. These prompts form FactBench, a dataset of 1K prompts spanning 150 topics and tiered into Easy, Moderate, and Hard prompts. We benchmark widely-used openweight and proprietary LMs from six families, yielding three key findings: (i) LMs' factual precision declines from Easy to Hard prompts, (ii) factuality does not necessarily improve with scale; Llama3.1-405B-Instruct performs comparably to or worse than its 70B variant, and (iii) Gemini1.5-Pro shows a notably higher refusal rate, with over-refusal in 25\% of cases.},
  eventtitle = {{{ACL}} 2025},
  isbn = {979-8-89176-251-0},
  file = {/Users/ale/Zotero/storage/MG9BNUA4/Fatahi Bayat et al. - 2025 - FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation.pdf}
}

@inproceedings{gangopadhyayTruthDareInvestigating2023,
  title = {Truth or {{Dare}}: {{Investigating Claims Truthfulness}} with {{ClaimsKG}}},
  shorttitle = {Truth or {{Dare}}},
  author = {Gangopadhyay, Susmita and Boland, Katarina and Dessí, Danilo and Dietze, Stefan and Fafalios, Pavlos and Tchechmedjiev, Andon and Todorov, Konstantin and Jabeen, Hajira},
  date = {2023-05-28},
  volume = {3401},
  url = {https://imt-mines-ales.hal.science/hal-04105799},
  urldate = {2025-08-27},
  abstract = {Searching and exploring online information is fundamental for our society. However, it is common to find inaccurate information on the Internet, that can quickly spread and be hard to identify. Fortunately, today, many fact-checking sources verify online information to provide online users with a means to recognize its truthfulness. These sources use different languages and scoring systems, which makes fact validation challenging and time-consuming. To address this issue, we propose a new release of ClaimsKG, a knowledge graph of about 59,580 claims, which covers 13 different fact-checking sources and provides a structured way to retrieve verified online claims. ClaimsKG is built using a pipeline that makes use of entity linking and disambiguation tools to fetch entities from DBpedia and an ad-hoc scoring normalization system. ClaimsKG is used as a showcase to provide the public with interesting and verified information about events of our times.},
  eventtitle = {{{D2R2}} 2023 - 2nd {{International Workshop}} on {{Linked Data-driven Resilience Research}}},
  langid = {english},
  file = {/Users/ale/Zotero/storage/7RZHMN23/Gangopadhyay et al. - 2023 - Truth or Dare Investigating Claims Truthfulness with ClaimsKG.pdf}
}

@online{hanRetrievalAugmentedGenerationGraphs2025,
  title = {Retrieval-{{Augmented Generation}} with {{Graphs}} ({{GraphRAG}})},
  author = {Han, Haoyu and Wang, Yu and Shomer, Harry and Guo, Kai and Ding, Jiayuan and Lei, Yongjia and Halappanavar, Mahantesh and Rossi, Ryan A. and Mukherjee, Subhabrata and Tang, Xianfeng and He, Qi and Hua, Zhigang and Long, Bo and Zhao, Tong and Shah, Neil and Javari, Amin and Xia, Yinglong and Tang, Jiliang},
  date = {2025-01-08},
  eprint = {2501.00309},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.00309},
  url = {http://arxiv.org/abs/2501.00309},
  urldate = {2025-08-27},
  abstract = {Retrieval-augmented generation (RAG) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic "nodes connected by edges" nature, encodes massive heterogeneous and relational information, making it a golden resource for RAG in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping RAG with Graph, i.e., GraphRAG. However, unlike conventional RAG, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing GraphRAG for different domains. Given the broad applicability, the associated design challenges, and the recent surge in GraphRAG, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on GraphRAG. Our survey first proposes a holistic GraphRAG framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review GraphRAG techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-RAG/GraphRAG/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/ale/Zotero/storage/BEAYEGTQ/Han et al. - 2025 - Retrieval-Augmented Generation with Graphs (GraphRAG).pdf;/Users/ale/Zotero/storage/YP3MKFNZ/2501.html}
}

@inproceedings{jiangKGAgentEfficientAutonomous2025,
  title = {{{KG-Agent}}: {{An Efficient Autonomous Agent Framework}} for {{Complex Reasoning}} over {{Knowledge Graph}}},
  shorttitle = {{{KG-Agent}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Jiang, Jinhao and Zhou, Kun and Zhao, Xin and Song, Yang and Zhu, Chen and Zhu, Hengshu and Wen, Ji-Rong},
  date = {2025},
  pages = {9505--9523},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.468},
  url = {https://aclanthology.org/2025.acl-long.468},
  urldate = {2025-08-27},
  eventtitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  langid = {english},
  file = {/Users/ale/Zotero/storage/ZIAELT3L/Jiang et al. - 2025 - KG-Agent An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph.pdf}
}

@online{linBioKGBenchKnowledgeGraph2024,
  title = {{{BioKGBench}}: {{A Knowledge Graph Checking Benchmark}} of {{AI Agent}} for {{Biomedical Science}}},
  shorttitle = {{{BioKGBench}}},
  author = {Lin, Xinna and Ma, Siqi and Shan, Junjie and Zhang, Xiaojing and Hu, Shell Xu and Guo, Tiannan and Li, Stan Z. and Yu, Kaicheng},
  date = {2024-06-29},
  eprint = {2407.00466},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.00466},
  url = {http://arxiv.org/abs/2407.00466},
  urldate = {2025-08-27},
  abstract = {Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models (LLMs). However, to evaluate such systems, people either rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical experimental manner. How to precisely benchmark biomedical agents from an AI Scientist perspective remains largely unexplored. To this end, we draw inspiration from one most important abilities of scientists, understanding the literature, and introduce BioKGBench. In contrast to traditional evaluation benchmark that only focuses on factual QA, where the LLMs are known to have hallucination issues, we first disentangle "Understanding Literature" into two atomic abilities, i) "Understanding" the unstructured text from research papers by performing scientific claim verification, and ii) Ability to interact with structured Knowledge-Graph Question-Answering (KGQA) as a form of "Literature" grounding. We then formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based Retrieval-Augmented Generation (RAG) to identify the factual errors of existing large-scale knowledge graph databases. We collect over two thousand data for two atomic tasks and 225 high-quality annotated data for the agent task. Surprisingly, we discover that state-of-the-art agents, both daily scenarios and biomedical ones, have either failed or inferior performance on our benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent. On the widely used popular knowledge graph, we discover over 90 factual errors which provide scenarios for agents to make discoveries and demonstrate the effectiveness of our approach. The code and data are available at https://github.com/westlake-autolab/BioKGBench.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/ale/Zotero/storage/G8JQTD8B/Lin et al. - 2024 - BioKGBench A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.pdf;/Users/ale/Zotero/storage/RMWSITTG/2407.html}
}

@inproceedings{linFACTAUDITAdaptiveMultiAgent2025,
  title = {{{FACT-AUDIT}}: {{An Adaptive Multi-Agent Framework}} for {{Dynamic Fact-Checking Evaluation}} of {{Large Language Models}}},
  shorttitle = {{{FACT-AUDIT}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Lin, Hongzhan and Deng, Yang and Gu, Yuxuan and Zhang, Wenxuan and Ma, Jing and Ng, See-Kiong and Chua, Tat-Seng},
  editor = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  date = {2025-07},
  pages = {360--381},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.17},
  url = {https://aclanthology.org/2025.acl-long.17/},
  urldate = {2025-08-27},
  abstract = {Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.},
  eventtitle = {{{ACL}} 2025},
  isbn = {979-8-89176-251-0},
  file = {/Users/ale/Zotero/storage/J9LQY9CD/Lin et al. - 2025 - FACT-AUDIT An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language.pdf}
}

@inproceedings{shamiFactVerificationKnowledge2025,
  title = {Fact {{Verification}} in {{Knowledge Graphs Using LLMs}}},
  booktitle = {Proceedings of the 48th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Shami, Farzad and Marchesin, Stefano and Silvello, Gianmaria},
  date = {2025-07-13},
  series = {{{SIGIR}} '25},
  pages = {3985--3989},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3726302.3730142},
  url = {https://doi.org/10.1145/3726302.3730142},
  urldate = {2025-08-27},
  abstract = {Automated fact-checking systems often struggle with trustworthiness, as they lack transparency in their reasoning processes and fail to handle relationships in data. This work presents FactCheck, a fact verification system topped by a web platform that shows how Large Language Models (LLMs) can be collectively used to verify facts within Knowledge Graphs (KGs). While the underlying verification engine implements a system that combines Retrieval Augmented Generation (RAG) with an ensemble of LLMs to validate KG facts, the platform focuses on making the results of this complex process as transparent and accessible as possible. Users can explore how different models interpret the same evidence, compare their reasoning patterns, and understand the factors that lead to the final verification result. The platform supports technical users who want to analyze the model behavior and general users who need to verify whether the facts in the dataset are correct.},
  isbn = {979-8-4007-1592-1},
  file = {/Users/ale/Downloads/2025-SIGIR_Demo_LLM.pdf}
}

@inproceedings{thibaultGuideMisinformationDetection2025,
  title = {A {{Guide}} to {{Misinformation Detection Data}} and {{Evaluation}}},
  booktitle = {Proceedings of the 31st {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining V}}.2},
  author = {Thibault, Camille and Tian, Jacob-Junqi and Péloquin-Skulski, Gabrielle and Curtis, Taylor Lynn and Zhou, James and Laflamme, Florence and Guan, Luke Yuxiang and Rabbany, Reihaneh and Godbout, Jean-François and Pelrine, Kellin},
  date = {2025-08-03},
  pages = {5801--5809},
  publisher = {ACM},
  location = {Toronto ON Canada},
  doi = {10.1145/3711896.3737437},
  url = {https://dl.acm.org/doi/10.1145/3711896.3737437},
  urldate = {2025-08-27},
  eventtitle = {{{KDD}} '25: {{The}} 31st {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {979-8-4007-1454-2},
  langid = {english},
  file = {/Users/ale/Zotero/storage/UFM2J3X2/Thibault et al. - 2025 - A Guide to Misinformation Detection Data and Evaluation.pdf}
}
