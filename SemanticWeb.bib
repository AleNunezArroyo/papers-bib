@incollection{burelCimpleKGContinuouslyUpdated2025,
  title = {{{CimpleKG}}: {{A Continuously Updated Knowledge Graph}} on {{Misinformation}}, {{Factors}} and {{Fact-Checks}}},
  shorttitle = {{{CimpleKG}}},
  booktitle = {The {{Semantic Web}} – {{ISWC}} 2024},
  author = {Burel, Grégoire and Mensio, Martino and Peskine, Youri and Troncy, Raphael and Papotti, Paolo and Alani, Harith},
  editor = {Demartini, Gianluca and Hose, Katja and Acosta, Maribel and Palmonari, Matteo and Cheng, Gong and Skaf-Molli, Hala and Ferranti, Nicolas and Hernández, Daniel and Hogan, Aidan},
  date = {2025},
  volume = {15233},
  pages = {97--114},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-77847-6_6},
  url = {https://link.springer.com/10.1007/978-3-031-77847-6_6},
  urldate = {2025-08-27},
  isbn = {978-3-031-77846-9 978-3-031-77847-6},
  langid = {english},
  file = {/Users/ale/Zotero/storage/Q5IXCKQ2/Burel et al. - 2025 - CimpleKG A Continuously Updated Knowledge Graph on Misinformation, Factors and Fact-Checks.pdf}
}

@online{chenCanLLMGeneratedMisinformation2024,
  title = {Can {{LLM-Generated Misinformation Be Detected}}?},
  author = {Chen, Canyu and Shu, Kai},
  date = {2024-04-23},
  eprint = {2309.13788},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.13788},
  url = {http://arxiv.org/abs/2309.13788},
  urldate = {2025-08-28},
  abstract = {The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures.},
  pubstate = {prepublished},
  version = {5},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/ale/Zotero/storage/LILNRKHG/Chen and Shu - 2024 - Can LLM-Generated Misinformation Be Detected.pdf;/Users/ale/Zotero/storage/P6CL8TS5/2309.html}
}

@article{chenCombatingMisinformationAge2024,
  title = {Combating Misinformation in the Age of {{LLMs}}: {{Opportunities}} and Challenges},
  shorttitle = {Combating Misinformation in the Age of {{LLMs}}},
  author = {Chen, Canyu and Shu, Kai},
  date = {2024},
  journaltitle = {AI Magazine},
  volume = {45},
  number = {3},
  pages = {354--368},
  issn = {2371-9621},
  doi = {10.1002/aaai.12188},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aaai.12188},
  urldate = {2025-08-28},
  abstract = {Misinformation such as fake news and rumors is a serious threat for information ecosystems and public trust. The emergence of large language models (LLMs) has great potential to reshape the landscape of combating misinformation. Generally, LLMs can be a double-edged sword in the fight. On the one hand, LLMs bring promising opportunities for combating misinformation due to their profound world knowledge and strong reasoning abilities. Thus, one emerging question is: can we utilize LLMs to combat misinformation? On the other hand, the critical challenge is that LLMs can be easily leveraged to generate deceptive misinformation at scale. Then, another important question is: how to combat LLM-generated misinformation? In this paper, we first systematically review the history of combating misinformation before the advent of LLMs. Then we illustrate the current efforts and present an outlook for these two fundamental questions, respectively. The goal of this survey paper is to facilitate the progress of utilizing LLMs for fighting misinformation and call for interdisciplinary efforts from different stakeholders for combating LLM-generated misinformation.},
  langid = {english},
  file = {/Users/ale/Zotero/storage/UYKRK77Q/Chen and Shu - 2024 - Combating misinformation in the age of LLMs Opportunities and challenges.pdf;/Users/ale/Zotero/storage/HGMLGDUX/aaai.html}
}

@inproceedings{chenReviewApplicationsKnowledge2023,
  title = {Review on {{Applications}} of {{Knowledge Graph}} in {{Software Development}}},
  booktitle = {2023 6th {{International Symposium}} on {{Autonomous Systems}} ({{ISAS}})},
  author = {Chen, Zhihua and Zhao, Ming and Yang, Luchang and Xu, Fan and Ji, Hongxia and Wu, Peiya and Zhang, Kai and Dong, Xiaogang and Li, Xiaofeng},
  date = {2023-06},
  pages = {1--7},
  doi = {10.1109/ISAS59543.2023.10164597},
  url = {https://ieeexplore.ieee.org/document/10164597},
  urldate = {2025-08-27},
  abstract = {Knowledge graph (KG) can represent the domain knowledge in the structural entities and relations and have become a popular AI technique. Software knowledge provides a deep understanding of the software development process. In this paper, we firstly provide a brief review on the related techniques, construction methods and applications of KG in the software development process. Then, we detailedly review and discuss the specific applications of KG in the whole software development process, including the phases of software requirement analysis, software design, software testing, software vulnerability detection, software bug detection and software fault diagnosis, respectively. Moreover, this paper provides some unsolved problems about the KG’s applications in the field of spacecraft control software development to facilitate future research.},
  eventtitle = {2023 6th {{International Symposium}} on {{Autonomous Systems}} ({{ISAS}})},
  keywords = {Autonomous systems,Computer bugs,Fault diagnosis,knowledge graph,Process control,requirement analysis,software,software bug detection,software design,Software design,software fault diagnosis,software testing,Software testing,software vulnerability detection,Space vehicles,spacecraft control},
  file = {/Users/ale/Zotero/storage/CGB6QN85/Chen et al. - 2023 - Review on Applications of Knowledge Graph in Software Development.pdf}
}

@online{edgeLocalGlobalGraph2025,
  title = {From {{Local}} to {{Global}}: {{A Graph RAG Approach}} to {{Query-Focused Summarization}}},
  shorttitle = {From {{Local}} to {{Global}}},
  author = {Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Metropolitansky, Dasha and Ness, Robert Osazuwa and Larson, Jonathan},
  date = {2025-02-19},
  eprint = {2404.16130},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.16130},
  url = {http://arxiv.org/abs/2404.16130},
  urldate = {2025-08-27},
  abstract = {The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as "What are the main themes in the dataset?", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text. Our approach uses an LLM to build a graph index in two stages: first, to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/Users/ale/Zotero/storage/AUEBTHJP/Edge et al. - 2025 - From Local to Global A Graph RAG Approach to Query-Focused Summarization.pdf;/Users/ale/Zotero/storage/786T67VS/2404.html}
}

@inproceedings{fatahibayatFactBenchDynamicBenchmark2025,
  title = {{{FactBench}}: {{A Dynamic Benchmark}} for {{In-the-Wild Language Model Factuality Evaluation}}},
  shorttitle = {{{FactBench}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Fatahi Bayat, Farima and Zhang, Lechen and Munir, Sheza and Wang, Lu},
  editor = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  date = {2025-07},
  pages = {33090--33110},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.1587},
  url = {https://aclanthology.org/2025.acl-long.1587/},
  urldate = {2025-08-27},
  abstract = {The rapid adoption of language models (LMs) across diverse applications has raised concerns about their factuality, i.e., their consistency with real-world facts. We introduce VERIFY, an evidence-based evaluation pipeline that measures LMs' factuality in real-world user interactions. VERIFY considers the verifiability of LM-generated content and categorizes content units as Supported, Unsupported, or Undecidable based on Web-retrieved evidence. Importantly, factuality judgment by VERIFY more strongly correlates with human evaluations than existing methods. Using VERIFY, we identify “hallucination prompts,” i.e., those that frequently elicit factual errors in LM responses. These prompts form FactBench, a dataset of 1K prompts spanning 150 topics and tiered into Easy, Moderate, and Hard prompts. We benchmark widely-used openweight and proprietary LMs from six families, yielding three key findings: (i) LMs' factual precision declines from Easy to Hard prompts, (ii) factuality does not necessarily improve with scale; Llama3.1-405B-Instruct performs comparably to or worse than its 70B variant, and (iii) Gemini1.5-Pro shows a notably higher refusal rate, with over-refusal in 25\% of cases.},
  eventtitle = {{{ACL}} 2025},
  isbn = {979-8-89176-251-0},
  file = {/Users/ale/Zotero/storage/MG9BNUA4/Fatahi Bayat et al. - 2025 - FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation.pdf}
}

@inproceedings{gangopadhyayTruthDareInvestigating2023,
  title = {Truth or {{Dare}}: {{Investigating Claims Truthfulness}} with {{ClaimsKG}}},
  shorttitle = {Truth or {{Dare}}},
  author = {Gangopadhyay, Susmita and Boland, Katarina and Dessí, Danilo and Dietze, Stefan and Fafalios, Pavlos and Tchechmedjiev, Andon and Todorov, Konstantin and Jabeen, Hajira},
  date = {2023-05-28},
  volume = {3401},
  url = {https://imt-mines-ales.hal.science/hal-04105799},
  urldate = {2025-08-27},
  abstract = {Searching and exploring online information is fundamental for our society. However, it is common to find inaccurate information on the Internet, that can quickly spread and be hard to identify. Fortunately, today, many fact-checking sources verify online information to provide online users with a means to recognize its truthfulness. These sources use different languages and scoring systems, which makes fact validation challenging and time-consuming. To address this issue, we propose a new release of ClaimsKG, a knowledge graph of about 59,580 claims, which covers 13 different fact-checking sources and provides a structured way to retrieve verified online claims. ClaimsKG is built using a pipeline that makes use of entity linking and disambiguation tools to fetch entities from DBpedia and an ad-hoc scoring normalization system. ClaimsKG is used as a showcase to provide the public with interesting and verified information about events of our times.},
  eventtitle = {{{D2R2}} 2023 - 2nd {{International Workshop}} on {{Linked Data-driven Resilience Research}}},
  langid = {english},
  file = {/Users/ale/Zotero/storage/7RZHMN23/Gangopadhyay et al. - 2023 - Truth or Dare Investigating Claims Truthfulness with ClaimsKG.pdf}
}

@inproceedings{gautamFactGeniusCombiningZeroShot2024,
  title = {{{FactGenius}}: {{Combining Zero-Shot Prompting}} and {{Fuzzy Relation Mining}} to {{Improve Fact Verification}} with {{Knowledge Graphs}}},
  shorttitle = {{{FactGenius}}},
  booktitle = {Proceedings of the {{Seventh Fact Extraction}} and {{VERification Workshop}} ({{FEVER}})},
  author = {Gautam, Sushant},
  date = {2024},
  eprint = {2406.01311},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {297--306},
  doi = {10.18653/v1/2024.fever-1.30},
  url = {http://arxiv.org/abs/2406.01311},
  urldate = {2025-09-12},
  abstract = {Fact-checking is a crucial natural language processing (NLP) task that verifies the truthfulness of claims by considering reliable evidence. Traditional methods are often limited by labour-intensive data curation and rule-based approaches. In this paper, we present FactGenius, a novel method that enhances fact-checking by combining zero-shot prompting of large language models (LLMs) with fuzzy text matching on knowledge graphs (KGs). Leveraging DBpedia, a structured linked data dataset derived from Wikipedia, FactGenius refines LLM-generated connections using similarity measures to ensure accuracy. The evaluation of FactGenius on the FactKG, a benchmark dataset for fact verification, demonstrates that it significantly outperforms existing baselines, particularly when fine-tuning RoBERTa as a classifier. The two-stage approach of filtering and validating connections proves crucial, achieving superior performance across various reasoning types and establishing FactGenius as a promising tool for robust fact-checking. The code and materials are available at https://github.com/SushantGautam/FactGenius.},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/ale/Zotero/storage/PTS96KAP/Gautam - 2024 - FactGenius Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification wit.pdf}
}

@online{hanRetrievalAugmentedGenerationGraphs2025,
  title = {Retrieval-{{Augmented Generation}} with {{Graphs}} ({{GraphRAG}})},
  author = {Han, Haoyu and Wang, Yu and Shomer, Harry and Guo, Kai and Ding, Jiayuan and Lei, Yongjia and Halappanavar, Mahantesh and Rossi, Ryan A. and Mukherjee, Subhabrata and Tang, Xianfeng and He, Qi and Hua, Zhigang and Long, Bo and Zhao, Tong and Shah, Neil and Javari, Amin and Xia, Yinglong and Tang, Jiliang},
  date = {2025-01-08},
  eprint = {2501.00309},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.00309},
  url = {http://arxiv.org/abs/2501.00309},
  urldate = {2025-08-27},
  abstract = {Retrieval-augmented generation (RAG) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic "nodes connected by edges" nature, encodes massive heterogeneous and relational information, making it a golden resource for RAG in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping RAG with Graph, i.e., GraphRAG. However, unlike conventional RAG, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing GraphRAG for different domains. Given the broad applicability, the associated design challenges, and the recent surge in GraphRAG, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on GraphRAG. Our survey first proposes a holistic GraphRAG framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review GraphRAG techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-RAG/GraphRAG/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/ale/Zotero/storage/BEAYEGTQ/Han et al. - 2025 - Retrieval-Augmented Generation with Graphs (GraphRAG).pdf;/Users/ale/Zotero/storage/YP3MKFNZ/2501.html}
}

@inproceedings{jiangKGAgentEfficientAutonomous2025,
  title = {{{KG-Agent}}: {{An Efficient Autonomous Agent Framework}} for {{Complex Reasoning}} over {{Knowledge Graph}}},
  shorttitle = {{{KG-Agent}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Jiang, Jinhao and Zhou, Kun and Zhao, Xin and Song, Yang and Zhu, Chen and Zhu, Hengshu and Wen, Ji-Rong},
  date = {2025},
  pages = {9505--9523},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.468},
  url = {https://aclanthology.org/2025.acl-long.468},
  urldate = {2025-08-27},
  eventtitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  langid = {english},
  file = {/Users/ale/Zotero/storage/ZIAELT3L/Jiang et al. - 2025 - KG-Agent An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph.pdf}
}

@inproceedings{kimFactKGFactVerification2023b,
  title = {{{FactKG}}: {{Fact Verification}} via {{Reasoning}} on {{Knowledge Graphs}}},
  shorttitle = {{{FactKG}}},
  booktitle = {Proceedings of the 61st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Kim, Jiho and Park, Sungjin and Kwon, Yeonsu and Jo, Yohan and Thorne, James and Choi, Edward},
  editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  date = {2023-07},
  pages = {16190--16206},
  publisher = {Association for Computational Linguistics},
  location = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.895},
  url = {https://aclanthology.org/2023.acl-long.895/},
  urldate = {2025-09-12},
  abstract = {In real world applications, knowledge graphs (KG) are widely used in various domains (e.g. medical applications and dialogue agents). However, for fact verification, KGs have not been adequately utilized as a knowledge source. KGs can be a valuable knowledge source in fact verification due to their reliability and broad applicability. A KG consists of nodes and edges which makes it clear how concepts are linked together, allowing machines to reason over chains of topics. However, there are many challenges in understanding how these machine-readable concepts map to information in text. To enable the community to better use KGs, we introduce a new dataset, FactKG: Fact Verificationvia Reasoning on Knowledge Graphs. It consists of 108k natural language claims with five types of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore, FactKG contains various linguistic patterns, including colloquial style claims as well as written style claims to increase practicality. Lastly, we develop a baseline approach and analyze FactKG over these reasoning types. We believe FactKG can advance both reliability and practicality in KG-based fact verification.},
  eventtitle = {{{ACL}} 2023},
  file = {/Users/ale/Zotero/storage/C9P8PD9R/Kim et al. - 2023 - FactKG Fact Verification via Reasoning on Knowledge Graphs.pdf}
}

@online{linBioKGBenchKnowledgeGraph2024,
  title = {{{BioKGBench}}: {{A Knowledge Graph Checking Benchmark}} of {{AI Agent}} for {{Biomedical Science}}},
  shorttitle = {{{BioKGBench}}},
  author = {Lin, Xinna and Ma, Siqi and Shan, Junjie and Zhang, Xiaojing and Hu, Shell Xu and Guo, Tiannan and Li, Stan Z. and Yu, Kaicheng},
  date = {2024-06-29},
  eprint = {2407.00466},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.00466},
  url = {http://arxiv.org/abs/2407.00466},
  urldate = {2025-08-27},
  abstract = {Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models (LLMs). However, to evaluate such systems, people either rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical experimental manner. How to precisely benchmark biomedical agents from an AI Scientist perspective remains largely unexplored. To this end, we draw inspiration from one most important abilities of scientists, understanding the literature, and introduce BioKGBench. In contrast to traditional evaluation benchmark that only focuses on factual QA, where the LLMs are known to have hallucination issues, we first disentangle "Understanding Literature" into two atomic abilities, i) "Understanding" the unstructured text from research papers by performing scientific claim verification, and ii) Ability to interact with structured Knowledge-Graph Question-Answering (KGQA) as a form of "Literature" grounding. We then formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based Retrieval-Augmented Generation (RAG) to identify the factual errors of existing large-scale knowledge graph databases. We collect over two thousand data for two atomic tasks and 225 high-quality annotated data for the agent task. Surprisingly, we discover that state-of-the-art agents, both daily scenarios and biomedical ones, have either failed or inferior performance on our benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent. On the widely used popular knowledge graph, we discover over 90 factual errors which provide scenarios for agents to make discoveries and demonstrate the effectiveness of our approach. The code and data are available at https://github.com/westlake-autolab/BioKGBench.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/ale/Zotero/storage/G8JQTD8B/Lin et al. - 2024 - BioKGBench A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science.pdf;/Users/ale/Zotero/storage/RMWSITTG/2407.html}
}

@inproceedings{linFACTAUDITAdaptiveMultiAgent2025,
  title = {{{FACT-AUDIT}}: {{An Adaptive Multi-Agent Framework}} for {{Dynamic Fact-Checking Evaluation}} of {{Large Language Models}}},
  shorttitle = {{{FACT-AUDIT}}},
  booktitle = {Proceedings of the 63rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Lin, Hongzhan and Deng, Yang and Gu, Yuxuan and Zhang, Wenxuan and Ma, Jing and Ng, See-Kiong and Chua, Tat-Seng},
  editor = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  date = {2025-07},
  pages = {360--381},
  publisher = {Association for Computational Linguistics},
  location = {Vienna, Austria},
  doi = {10.18653/v1/2025.acl-long.17},
  url = {https://aclanthology.org/2025.acl-long.17/},
  urldate = {2025-08-27},
  abstract = {Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.},
  eventtitle = {{{ACL}} 2025},
  isbn = {979-8-89176-251-0},
  file = {/Users/ale/Zotero/storage/J9LQY9CD/Lin et al. - 2025 - FACT-AUDIT An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language.pdf}
}

@article{lopez-borrullMappingImpactGenerative2025,
  title = {Mapping the {{Impact}} of {{Generative AI}} on {{Disinformation}}: {{Insights}} from a {{Scoping Review}}},
  shorttitle = {Mapping the {{Impact}} of {{Generative AI}} on {{Disinformation}}},
  author = {López-Borrull, Alexandre and Lopezosa, Carlos},
  date = {2025-09},
  journaltitle = {Publications},
  volume = {13},
  number = {3},
  pages = {33},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6775},
  doi = {10.3390/publications13030033},
  url = {https://www.mdpi.com/2304-6775/13/3/33},
  urldate = {2025-08-28},
  abstract = {This article presents a scoping review of the academic literature published between 2021 and 2024 on the intersection of generative artificial intelligence (AI) and disinformation. Drawing from 64 peer-reviewed studies, the review examines the current research landscape and identifies six key thematic areas: political disinformation and propaganda; scientific disinformation; fact-checking; journalism and the media; media literacy and education; and deepfakes. The findings reveal that generative AI plays a dual role: it enables the rapid creation and targeted dissemination of synthetic content but also offers new opportunities for detection, verification, and public education. Beyond summarizing research trends, this review highlights the broader societal and practical implications of generative AI in the context of information disorder. It outlines how AI tools are already reshaping journalism, challenging scientific communication, and transforming strategies for media literacy and fact-checking. The analysis also identifies key policy and governance challenges, particularly the need for coordinated responses from governments, platforms, educators, and civil society actors. By offering a structured overview of the field, the article enhances our understanding of how generative AI can both exacerbate and help mitigate disinformation, and proposes directions for research, regulation, and public engagement.},
  langid = {english},
  keywords = {ChatGPT,deepfakes,disinformation,fact-checking,generative AI},
  file = {/Users/ale/Zotero/storage/ZH3LVFVV/López-Borrull and Lopezosa - 2025 - Mapping the Impact of Generative AI on Disinformation Insights from a Scoping Review.pdf}
}

@inproceedings{opsahlFactFictionImproving2024,
  title = {Fact or {{Fiction}}? {{Improving Fact Verification}} with {{Knowledge Graphs}} through {{Simplified Subgraph Retrievals}}},
  shorttitle = {Fact or {{Fiction}}?},
  booktitle = {Proceedings of the {{Seventh Fact Extraction}} and {{VERification Workshop}} ({{FEVER}})},
  author = {Opsahl, Tobias Aanderaa},
  editor = {Schlichtkrull, Michael and Chen, Yulong and Whitehouse, Chenxi and Deng, Zhenyun and Akhtar, Mubashara and Aly, Rami and Guo, Zhijiang and Christodoulopoulos, Christos and Cocarascu, Oana and Mittal, Arpit and Thorne, James and Vlachos, Andreas},
  date = {2024-11},
  pages = {307--316},
  publisher = {Association for Computational Linguistics},
  location = {Miami, Florida, USA},
  doi = {10.18653/v1/2024.fever-1.32},
  url = {https://aclanthology.org/2024.fever-1.32/},
  urldate = {2025-09-12},
  abstract = {Despite recent success in natural language processing (NLP), fact verification still remains a difficult task. Due to misinformation spreading increasingly fast, attention has been directed towards automatically verifying the correctness of claims. In the domain of NLP, this is usually done by training supervised machine learning models to verify claims by utilizing evidence from trustworthy corpora. We present efficient methods for verifying claims on a dataset where the evidence is in the form of structured knowledge graphs. We use the FactKG dataset, which is constructed from the DBpedia knowledge graph extracted from Wikipedia. By simplifying the evidence retrieval process, from fine-tuned language models to simple logical retrievals, we are able to construct models that both require less computational resources and achieve better test-set accuracy.},
  file = {/Users/ale/Zotero/storage/J96YHMYV/Opsahl - 2024 - Fact or Fiction Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retri.pdf}
}

@inproceedings{tchechmedjievClaimsKGKnowledgeGraph2019,
  title = {{{ClaimsKG}}: {{A Knowledge Graph}} of {{Fact-Checked Claims}}},
  shorttitle = {{{ClaimsKG}}},
  booktitle = {{{ISWC}} 2019 - 18th {{International Semantic Web Conference}}},
  author = {Tchechmedjiev, Andon and Fafalios, Pavlos and Boland, Katarina and Gasquet, Malo and Zloch, Matthaus and Zapilko, Benjamin and Dietze, Stefan and Todorov, Konstantin},
  date = {2019-10},
  pages = {309--324},
  location = {Auckland, New Zealand},
  doi = {10.1007/978-3-030-30796-7_20},
  url = {https://hal.science/hal-02404153},
  urldate = {2025-09-09},
  abstract = {Various research areas at the intersection of computer and social sciences require a ground truth of contextualized claims labelled with their truth values in order to facilitate supervision, validation or reproducibility of approaches dealing, for example, with fact-checking or analysis of societal debates. So far, no reasonably large, up-to-date and queryable corpus of structured information about claims and related metadata is publicly available. In an attempt to fill this gap, we introduce ClaimsKG, a knowledge graph of fact-checked claims, which facilitates structured queries about their truth values, authors, dates, journalistic reviews and other kinds of metadata. ClaimsKG is generated through a semi-automated pipeline, which harvests data from popular fact-checking websites on a regular basis, annotates claims with related entities from DBpedia, and lifts the data to RDF using an RDF/S model that makes use of established vocabularies. In order to harmonise data originating from diverse fact-checking sites, we introduce normalised ratings as well as a simple claims coreference resolution strategy. The current knowledge graph, extensible to new information, consists of 28,383 claims published since 1996, amounting to 6,606,032 triples.},
  keywords = {Claims,Fact-checking,Knowledge Graphs,Societal debates},
  file = {/Users/ale/Zotero/storage/5NF86GNZ/Tchechmedjiev et al. - 2019 - ClaimsKG A Knowledge Graph of Fact-Checked Claims.pdf}
}

@inproceedings{thibaultGuideMisinformationDetection2025,
  title = {A {{Guide}} to {{Misinformation Detection Data}} and {{Evaluation}}},
  booktitle = {Proceedings of the 31st {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining V}}.2},
  author = {Thibault, Camille and Tian, Jacob-Junqi and Péloquin-Skulski, Gabrielle and Curtis, Taylor Lynn and Zhou, James and Laflamme, Florence and Guan, Luke Yuxiang and Rabbany, Reihaneh and Godbout, Jean-François and Pelrine, Kellin},
  date = {2025-08-03},
  pages = {5801--5809},
  publisher = {ACM},
  location = {Toronto ON Canada},
  doi = {10.1145/3711896.3737437},
  url = {https://dl.acm.org/doi/10.1145/3711896.3737437},
  urldate = {2025-08-27},
  eventtitle = {{{KDD}} '25: {{The}} 31st {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {979-8-4007-1454-2},
  langid = {english},
  file = {/Users/ale/Zotero/storage/UFM2J3X2/Thibault et al. - 2025 - A Guide to Misinformation Detection Data and Evaluation.pdf}
}
